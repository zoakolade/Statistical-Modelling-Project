{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the data from Part 1 with the data from Part 2 to create a new dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns                      \n",
    "import matplotlib.pyplot as plt             \n",
    "%matplotlib inline     \n",
    "sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_city_bikes = pd.read_csv('city_bikes_portland.csv')\n",
    "df_foursquare = pd.read_csv('foursquare.csv')\n",
    "df_yelp = pd.read_csv('yelp.csv')\n",
    "#joining on a composite key of columns 'bike_station_location','name','address' inorder to get a unique key to join on\n",
    "df_first_join = pd.merge(df_yelp, df_foursquare, on=['bike_station_location','name','address'], how='inner')\n",
    "df_final_join = pd.merge(df_first_join, df_city_bikes, on='bike_station_location', how='left')\n",
    "df_final_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Refined the resultant merged dataframe through the removal of extraneous columns, while retaining 'main_category_y' for its potential to offer more detailed category combinations. Retained 'latitude' and 'longitude' as they hold the potential for future analysis. Assessed and addressed missing values by opting to retain rows containing NaN values, given the potential influence of other data in the same row on the statistical model. Scrutinized and resolved duplicate rows. Additionally, identified and addressed potential outliers. In this context, exclusively considered distance values that lie beyond the 1000m radius as outliers, aligning with the intention to exclude data outside this radius from the statistical model.\n",
    "df_final_join.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this results shows that there at 0 duplicated rows, so nothing was dropped\n",
    "df_final_join.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking to see if there are any outliers in the distance col, since these are the only outliers\n",
    "#that would be good to remove from the dataset since we only want data within 1000m\n",
    "sns.boxplot(x=df_final_cleaned['distance_away_x'])\n",
    "print(np.where((df_final_cleaned['distance_away_x']>1000) & (df_final_cleaned['distance_away_x']<0)))\n",
    "#this shows that there are no distance values > 1000m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_cleaned = df_final_join.drop(['distance_away_y'], axis=1)\n",
    "df_final_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporting to csv file for future use\n",
    "df_final_cleaned.to_csv('joined_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide a visualization that you used as part of your EDA process. Explain the initial pattern or relationship you discoved through this visualization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from this boxplot we can see that there are a few distances that are considered outliers based on our dataset distribution,\n",
    "#but none of them are over 1000m, so they were kept in since the dataset is suppose to include everything up to 1000m\n",
    "sns.boxplot(x=df_final_cleaned['distance_away_x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from this scatter plot of distance away vs review count, the initial pattern discovered with this visualization is that\n",
    "#there are more higher number review counts for places that are closer to a bikestation, which is expected.\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "ax.scatter(df_final_cleaned['distance_away_x'], df_final_cleaned['review_count'])\n",
    "ax.set_xlabel('distance_away')\n",
    "ax.set_ylabel('review_count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from this scatter plot of total possible bikes vs review count, the initial pattern discovered with this visualization is that\n",
    "#there does not seem to be a pattern or relationship between the total possible bikes at a station and the number of reviews a business \n",
    "#within a 1000m radius of the bike station gets.\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "ax.scatter(df_final_cleaned['num_of_bikes'], df_final_cleaned['review_count'])\n",
    "ax.set_xlabel('num_of_bikes')\n",
    "ax.set_ylabel('review_count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put all your results in an SQLite3 database (remember, SQLite stores its databases as files in your local machine - make sure to create your database in your project's data/ directory!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "\n",
    "def create_connection(path):\n",
    "    connection = None\n",
    "    try:\n",
    "        connection = sqlite3.connect(path)\n",
    "        print(\"Connection to SQLite DB successful\")\n",
    "    except Error as e:\n",
    "        print(f\"The error '{e}' occurred\")\n",
    "\n",
    "    return connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = create_connection(\"../data/city_bike_POI.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_city_bikes_portland_table = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS city_bikes_portland (\n",
    "  bike_station_location TEXT,\n",
    "  latitude FLOAT,\n",
    "  longitude FLOAT,\n",
    "  num_of_bikes INTEGER\n",
    ");\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"../data/city_bike_POI.sqlite\")\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute(create_city_bikes_portland_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_city_bikes.to_sql('city_bikes_portland', conn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_foursquare_table = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS foursquare (\n",
    "  bike_station_location TEXT,\n",
    "  name TEXT,\n",
    "  main_category TEXT,\n",
    "  address TEXT,\n",
    "  distance_away INTEGER\n",
    ");\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute(create_foursquare_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_foursquare.to_sql('foursquare', conn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c.execute(\"\"\"SELECT * FROM foursquare\"\"\")\n",
    "#c.fetchall()\n",
    "create_yelp_table = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS yelp (\n",
    "  bike_station_location TEXT,\n",
    "  name TEXT,\n",
    "  main_category TEXT,\n",
    "  address TEXT,\n",
    "  price TEXT,\n",
    "  rating FLOAT,\n",
    "  review_count INTEGER,\n",
    "  status TEXT,\n",
    "  distance_away FLOAT\n",
    ");\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute(create_yelp_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yelp.to_sql('yelp', conn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_joined_table = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS joined (\n",
    "  bike_station_location TEXT,\n",
    "  name TEXT,\n",
    "  main_category_x TEXT,\n",
    "  address TEXT,\n",
    "  price TEXT,\n",
    "  rating FLOAT,\n",
    "  review_count INTEGER,\n",
    "  status TEXT,\n",
    "  distance_away_x FLOAT,\n",
    "  main_category_y TEXT,\n",
    "  latitude FLOAT,\n",
    "  longitude FLOAT,\n",
    "  num_of_bikes INTEGER\n",
    ");\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute(create_joined_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_cleaned.to_sql('joined', conn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking to see if data was inserted correctly\n",
    "c.execute(\"\"\"SELECT * FROM joined\"\"\")\n",
    "c.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the data before and after the join to validate your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking to see if NaN values exist in the data before and after joining\n",
    "print(df_final_cleaned.isnull().values.any(), df_city_bikes.isnull().values.any(), df_foursquare.isnull().values.any(),\n",
    "      df_yelp.isnull().values.any())\n",
    "#we can see that NaN values existed in 2 of the 3 dataframes that were joined and the joined data framed also has NaN values,\n",
    "#which validates our join. Rows with NaN values were kept in since other data in those rows can have an impact on the statistical model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking to see if there are any duplicate rows in our resulting joined data\n",
    "df_final_cleaned.duplicated().values.any()\n",
    "#we can see that there are no duplicated rows in the final joined data, which valids the composite key that the tables were joined on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking to see if the number of rows in the data after joining is less than the rows from the 2 tables joined with \n",
    "#the composite key\n",
    "print(df_foursquare.shape, df_yelp.shape, df_final_cleaned.shape)\n",
    "#We can see that the joined dataframe has much less rows, which makes sense and validates that our composite key \n",
    "#was infact a good unique key"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
